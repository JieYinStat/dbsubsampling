[{"path":"https://jieyinstat.github.io/dbsubsampling/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://jieyinstat.github.io/dbsubsampling/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://jieyinstat.github.io/dbsubsampling/articles/CompareComputeTime.html","id":"iboss","dir":"Articles","previous_headings":"","what":"IBOSS","title":"CompareComputeTime","text":"IBOSS used user interface package, also write functions based different styles compare computation efficiency. myR_IBOSS: Written package use base R. myRcpp_IBOSS: Written package use Rcpp like r style (Vectorization far possible). myRcpp_cstyle_IBOSS: Written package use Rcpp like C++ style (loops scalar far possible). myArma_IBOSS: Written package use RcppArmadillo like r style (Vectorization far possible). IBOSS: Quoted Yu et.al.(2022) (core code adapted Wang et.al.(2019)) use Rcpp core code C++ style (mainly loops scalars).  IBOSS relatively simple require much computation row. use C++ seem improve efficiency significantly, slow fast: myRcpp_IBOSS: Although Rcpp used, use many C++ features, mainly vector operations, many steps inside function optimized, efficiency low. myRcpp_cstyle_IBOSS: Using Rcpp C++ features, heavy use loops. efficiency high, possibly many custom functions inside function, implementation method efficient enough. myArma_IBOSS: Despite use RcppArmadillo, function interior still R-style take advantage C++ effects. myR_IBOSS: Make use R’s native functions much possible, use internal compilation optimization improve computation speed. IBOSS: Although called Rcpp form, internal functions written C++ style mainly loop scalars. calculation speed remarkably fast.","code":"Size <- c(100, 200, 500, 750, 1000, 2000, 5000, 7500, 10000,  15000, 20000)  time_IBOSS <- numeric(length(Size)) time_myR_IBOSS <- numeric(length(Size)) time_myRcpp_IBOSS <- numeric(length(Size)) time_myArma_IBOSS <- numeric(length(Size)) time_myRcpp_cstyle_IBOSS <- numeric(length(Size)) for (i in seq_along(Size)){   # paste0(\"Size: \", Size[i])   begin <- Sys.time(); index <- IBOSS(Size[i], X); time_IBOSS[i] <- Sys.time() - begin;   begin <- Sys.time(); index <- myR_IBOSS(Size[i], X); time_myR_IBOSS[i] <- Sys.time() - begin;   begin <- Sys.time(); index <- myRcpp_IBOSS(Size[i], X); time_myRcpp_IBOSS[i] <- Sys.time() - begin;   begin <- Sys.time(); index <- myArma_IBOSS(Size[i], X); time_myArma_IBOSS[i] <- Sys.time() - begin;   begin <- Sys.time(); index <- myRcpp_cstyle_IBOSS(Size[i], X); time_myRcpp_cstyle_IBOSS[i] <- Sys.time() - begin; }  time_IBOSS <- data.frame(Size, time_IBOSS, time_myR_IBOSS, time_myRcpp_IBOSS,                           time_myArma_IBOSS, time_myRcpp_cstyle_IBOSS) time_IBOSS <- time_IBOSS %>%    pivot_longer(-Size, names_to = \"Method\", values_to = \"Time\") ggplot(data = time_IBOSS, aes(x = Size, y = Time, group = Method, color = Method)) +   geom_line()"},{"path":"https://jieyinstat.github.io/dbsubsampling/articles/CompareComputeTime.html","id":"oss","dir":"Articles","previous_headings":"","what":"OSS","title":"CompareComputeTime","text":"OSS used user interface package, also write functions based different styles compare computation efficiency. OSS: Written package use Rcpp. myR_OSS: Written package use base R. myArma_OSS: Quoted Zhu et.al.(2023) use RcppArmadillo.  OSS contains large number loops rows dynamics vector changes. advantages C++ obvious, slow fast: myR_OSS: R good looping (memory allocation loops leads slow speeds) good handling dynamic vector changes. OSS: Using Rcpp significantly increases speed. myArma_OSS: RcppArmadillo calls C++ Armadillo library, internal algorithm efficient, suitable large scale computing. seems Rcpp better results, RcppArmadillo optimized.","code":"Size <- c(100, 200, 500, 750, 1000)  time_OSS <- numeric(length(Size)) time_myR_OSS <- numeric(length(Size)) time_myArma_OSS <- numeric(length(Size)) for (i in seq_along(Size)){   # paste0(\"Size: \", Size[i])   begin <- Sys.time(); index <- OSS(Size[i], X); time_OSS[i] <- Sys.time() - begin;   begin <- Sys.time(); index <- myR_OSS(Size[i], X); time_myR_OSS[i] <- Sys.time() - begin;   begin <- Sys.time(); index <- myArma_OSS(Size[i], X); time_myArma_OSS[i] <- Sys.time() - begin }  time_OSS <- data.frame(Size, time_OSS, time_myR_OSS, time_myArma_OSS) time_OSS <- time_OSS %>%    pivot_longer(-Size, names_to = \"Method\", values_to = \"Time\") ggplot(data = time_OSS, aes(x = Size, y = Time, group = Method, color = Method)) +   geom_line()"},{"path":"https://jieyinstat.github.io/dbsubsampling/articles/IES_Simulation.html","id":"test-the-compilation-environment-","dir":"Articles","previous_headings":"","what":"Test the compilation environment.","title":"IES_Simulation","text":"Since brochure built github remote server, let’s first test setup server. ’ll write small snippet code check works github remote server. Mainly mclapply doesn’t run windows, addition testing see parallel computation possible estimating running time.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/articles/IES_Simulation.html","id":"nonparallel","dir":"Articles","previous_headings":"Test the compilation environment.","what":"Nonparallel:","title":"IES_Simulation","text":"","code":"data <- data_IES_Case_1_Train start_time <- Sys.time() result <- lapply(1:50000, function(x) lm(y ~. , data = data)[[\"coefficients\"]][1]) print(Sys.time() -  start_time) #> Time difference of 1.6658 mins"},{"path":"https://jieyinstat.github.io/dbsubsampling/articles/IES_Simulation.html","id":"parallel-with-2-cores","dir":"Articles","previous_headings":"Test the compilation environment.","what":"Parallel with 2 cores:","title":"IES_Simulation","text":"","code":"data <- data_IES_Case_1_Train start_time <- Sys.time() result <- mclapply(1:50000, function(x) lm(y ~. , data = data)[[\"coefficients\"]][1], mc.cores = 2) print(Sys.time() -  start_time) #> Time difference of 53.34155 secs"},{"path":"https://jieyinstat.github.io/dbsubsampling/articles/IES_Simulation.html","id":"parallel-with-5-cores","dir":"Articles","previous_headings":"Test the compilation environment.","what":"Parallel with 5 cores:","title":"IES_Simulation","text":"don’t know many cores remote server can assign us. trying, remote server assign us multiple cores, five cores seemed fastest locally appropriate number.","code":"data <- data_IES_Case_1_Train start_time <- Sys.time() result <- mclapply(1:50000, function(x) lm(y ~. , data = data)[[\"coefficients\"]][1], mc.cores = 5) print(Sys.time() -  start_time) #> Time difference of 41.17567 secs"},{"path":[]},{"path":"https://jieyinstat.github.io/dbsubsampling/articles/IES_Simulation.html","id":"seed-setting","dir":"Articles","previous_headings":"Implement with R or Rcpp","what":"Seed Setting","title":"IES_Simulation","text":"IES absolutely deterministic sampling method, pay attention setting random seeds.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/articles/IES_Simulation.html","id":"compare-running-time","dir":"Articles","previous_headings":"Implement with R or Rcpp","what":"Compare Running Time","title":"IES_Simulation","text":"problem setting random seed R C++, directly check whether results R Rcpp . change random steps pick first element(r_IES_compare c_IES_compare), get result R Rcpp, proves correctness codes. can compare running time R Rcpp (fact RcppArmadillo): RcppArmadillo greatly improves speed. use RcppArmadillo main function.","code":"X_compare <- dbsubsampling::data_IES_Case_1_Train[, c(\"X1\", \"X2\", \"X3\")] n <- 1000; q <- 16;  bench_result <- bench::mark(   dbsubsampling::r_IES_compare(X_compare, n, q),   dbsubsampling::c_IES_compare(X_compare, n, q),   iterations = 10 ) bench_result[c(\"expression\", \"min\", \"median\", \"mem_alloc\", \"n_gc\")] #> # A tibble: 2 × 4 #>   expression                                         min   median mem_alloc #>   <bch:expr>                                    <bch:tm> <bch:tm> <bch:byt> #> 1 dbsubsampling::r_IES_compare(X_compare, n, q)    18.7s    19.4s     1.1GB #> 2 dbsubsampling::c_IES_compare(X_compare, n, q)  110.1ms  110.8ms    1.52MB"},{"path":"https://jieyinstat.github.io/dbsubsampling/articles/IES_Simulation.html","id":"addition-compare","dir":"Articles","previous_headings":"Implement with R or Rcpp","what":"Addition compare","title":"IES_Simulation","text":"authors IES wrote sampling program python, roughly compare: can see python fast C++, much faster R. (reason simply output results without running code complexity additional setup required use python programs package.)","code":"reticulate::source_python(\"/Users/jie/Desktop/IES/IES_supp/ies.py\") get.lat= function(x, snew=16) {    s0=max(x)-min(x)   lat=floor((x-min(x))/(s0/snew))   lat[lat==snew]=snew-1   lat } py_IES <- function(x, k){   xl=apply(x,2,get.lat)   n = nrow(x)   initial=c(sample(1:n,1))   ies=Uclab(xl,k,ini=initial-1)+1    return(ies) } system.time(lapply(1:10, function(i) py_IES(X_case1,n)))  # user     system   elapsed  # 2.506    0.435    2.956 system.time(lapply(1:10, function(i) c_IES(X_case1,n,q=16))) # user     system   elapsed  # 0.374    0.001    0.376  system.time(lapply(1:10, function(i) r_IES(X_case1,n,q=16))) # user     system   elapsed  # 77.587   0.665    78.636"},{"path":[]},{"path":"https://jieyinstat.github.io/dbsubsampling/articles/IES_Simulation.html","id":"data-description","dir":"Articles","previous_headings":"Numeric Simulation","what":"Data Description","title":"IES_Simulation","text":"use functions \\(m_1\\) \\(m_2\\), \\(m_3\\) present three component functions. gene_data generates data distributions. gene_grid_data generates data grid. Concretely, response generated : \\[ y = m(X) + \\epsilon, \\] \\[ m(X) = m_1(X_1) + m_2(X_2) + m_3(X_3) = \\frac{8}{4 + X_1} + \\frac{\\exp(3-X^2_2)}{4} + 1.5\\sin(\\frac{\\pi}{2}X_3), \\] \\(\\epsilon\\) follows \\(N(0, \\sigma^2)\\), variance \\(\\sigma^2=0.25\\). Case1: (gene_data parameter distribute = \"normal\") \\(x\\) generates truncated multivariate normal distribution \\(TN(0, \\Sigma, -2, 2)\\) , mean zero covariance matrix \\(\\Sigma=(0.3^{\\mathbb{1}(\\ne j)})\\) , predictor lies \\([-2, 2]\\). (use function TruncatedNormal::rtmvnorm. ) Case2: (gene_data parameter distribute = \"exp\") \\(x\\) generates truncated multivariate exponential distribution covariance matrix case 1. marginal distribution exponential distribution rate 1, truncated 4 translated \\([-2, 2]\\). (use R package copula function ellipCopula rCopula. ) two test data sets: Grid: grid consist \\(10^6\\) points predictor spanning 100 evenly spaced points \\([-1.75, 1.75]\\). Distribution: random sample 5000 points generated distribution full data. write auxiliary functions implement cross validation(CV) get evaluation measures. ase computes average squared error \\[ \\text{ASE}= \\sum_{x \\\\mathcal{X}_{test}} (\\hat{m}(x)-m(x))^2 / \\left| \\mathcal{X}_{test} \\right| \\] mee computes maximum estimation error: \\[ \\text{MEE} = \\max_{x \\\\mathcal{X}_{test}} \\left| \\hat{m}(x) - m(x) \\right| \\] create_folds create folds CV. get_opt_h get optimal bandwidth (fact span parameter function gam::gam). time-consuming step entire procedure. try use apply substitute loop get_opt_h , didn’t lead significant improvements. handle_outlier=TRUE, find index first occurrence maximum minimum values predictor, move data test set training set. get_result provide unified surface get MEE ASE two test data sets. full data size \\(N=10000\\) \\(p=3\\) predictors. Hyper-parameter set \\(q=16\\). bandwidth searched \\(\\{0.05, 0.1, \\dots, 0.95\\}\\) every predictor chosen five-fold CV. method trained subsamples \\(n=1000\\) , evaluated two test sets size \\(10^6\\) (grid) 5000 (distribute). save time, repeat simulation \\(S=5\\) times. simulation generate new full data new test data. Although IES LowCon carry randomness (IES due random selection initial values LowCon due initial space-filling design randomly constructed). However, randomness significant, can approximated deterministic approach, dataset considered regenerated time. tried using dataset across simulations found similar results obtained, IES consistently outperforming methods MEE ASE. LowCon need space-filling design, may need try use different initial designs. LowCon used lhs::randomLHD function generate space-filling design. original IES simulation used Sobol sequence generate space-filling design (spacefillr::generate_sobol_owen_set). Sobol seems better, least need less time implies faster convergence. LowCon used randomLHD function generate space-filling design, original IES simulation used Sobol sequence generate space-filling design. Upon attempts found little difference effectiveness two initial designs. package pbmcapply based parallel provides progress bar monitor running process. pbmcapply::pbmclapply function runs forking mode 5 cores (forking approach works POSIX systems (Mac, Linux, Unix, BSD) Windows). didn’t consider extrapolation numeric simulation. Although support model based subsamples smaller, range grid test set set far away boundary, unlikely outside boundary. distributed test set similar training set, fewer points boundary. won’t huge error.","code":"m1 <- function(x) {   8 / (4 + x) }  m2 <- function(x) {   exp(3 - x^2) / 4 }  m3 <- function(x) {   1.5*sin(pi / 2 * x) }  trans_exp_data <- function(density, lower, upper) {   out <- qexp( pexp(lower) + density*(pexp(upper) - pexp(lower)) )   return(out) }  gene_data <- function(N, rho, lower, upper, sd, distribute = \"normal\") {   cov <- matrix(rho, 3, 3) + diag(1-rho, 3)   if (distribute == \"normal\") {     x <- TruncatedNormal::rtmvnorm(N, rep(0, 3), cov, lb = rep(lower, 3), ub = rep(upper, 3))   } else if (distribute == \"exp\") {     copula_def <- copula::ellipCopula(family = \"normal\", dim = 3, dispstr = \"ex\", param = rho)     temp_quan <- copula::rCopula(N, copula_def)     x <- apply(temp_quan, 2, trans_exp_data, 0, (upper-lower)) - (upper-lower)/2   }      colnames(x) <- c(\"X1\", \"X2\", \"X3\")   m <- 1 + m1(x[, \"X1\"]) + m2(x[, \"X2\"]) + m3(x[, \"X3\"])   epi <- rnorm(N, 0, sd)   y <- m + epi   data <- as.data.frame(cbind(x, m = m , y = y))     return(data) } gene_grid_data <- function(lower, upper, one_dim_length, sd) {   one_dim_seq <- seq(lower, upper, length.out = one_dim_length)   x <- expand.grid(X1 = one_dim_seq, X2 = one_dim_seq, X3 = one_dim_seq, KEEP.OUT.ATTRS = FALSE)   m <- 1 + m1(x[, \"X1\"]) + m2(x[, \"X2\"]) + m3(x[, \"X3\"])   n_data <- nrow(x)   epi <- rnorm(n_data, 0, sd)   y <- m + epi   data <- as.data.frame(cbind(x, m = m , y = y))   return(data) } N <- 10000; n <- 1000; test_distribute_num <- 5000;  p <- 3; lower <- -2; upper <- 2; rho <- 0.3; sd = 0.5; K <- 5; one_dim_seq <- seq(0.05, 0.95, length.out = 10) h_grid <- expand.grid(one_dim_seq, one_dim_seq, one_dim_seq, KEEP.OUT.ATTRS = FALSE)"},{"path":"https://jieyinstat.github.io/dbsubsampling/articles/IES_Simulation.html","id":"case-1-truncated-normal-distribution","dir":"Articles","previous_headings":"Numeric Simulation","what":"Case 1: Truncated Normal Distribution","title":"IES_Simulation","text":"compute simulation result case 1 plot barplots MEE ASE two test datasets based three subsampling methods: Unif: Random sampling without replacement. LowCon: LowCon (LowCon: Design-based Subsampling Approach Misspecified Linear Model). IES: IES (Independence-Encouraging Subsampling Nonparametric Additive Models).","code":"test_grid <- gene_grid_data(lower = -1.75, upper = 1.75,                              one_dim_length = 100, sd = 0.25) get_combine_result <- function(i) {   data_train <- gene_data(N, rho, lower, upper, sd, \"normal\")   test_distribute <- gene_data(test_distribute_num, rho, lower, upper, sd, \"normal\")   rbind(get_result(\"Unif\", data_train, n, K, h_grid, test_distribute, test_grid),         get_result(\"LowCon\", data_train, n, K, h_grid, test_distribute, test_grid),         get_result(\"IES\", data_train, n, K, h_grid, test_distribute, test_grid)) }  Case1_time_start <- Sys.time() result_case_1 <- parallel::mclapply(1:5, get_combine_result, mc.cores = 5) print(Sys.time() - Case1_time_start) #> Time difference of 19.92717 mins result <- do.call(rbind, result_case_1) %>%    as.data.frame() %>%    dplyr::mutate(dplyr::across(!Method, as.double),          Method = factor(Method)) %>%    tidyr::pivot_longer(!Method, names_to = \"Measure\", values_to = \"Value\")"},{"path":"https://jieyinstat.github.io/dbsubsampling/articles/IES_Simulation.html","id":"distribution-testset","dir":"Articles","previous_headings":"Numeric Simulation > Case 1: Truncated Normal Distribution","what":"Distribution Testset","title":"IES_Simulation","text":"MEE distribution test set:  ASE distribution test set.","code":"ggplot(data = dplyr::filter(result, Measure == \"MEE_distribute\"), aes(x = Method, y = Value, color = Method)) +    geom_boxplot() + ggtitle(\"Case1_MEE_Distribute\") ggplot(data = dplyr::filter(result, Measure == \"ASE_distribute\"), aes(x = Method, y = Value, color = Method)) +    geom_boxplot() + ggtitle(\"Case1_ASE_Distribute\")"},{"path":"https://jieyinstat.github.io/dbsubsampling/articles/IES_Simulation.html","id":"grid-testset","dir":"Articles","previous_headings":"Numeric Simulation > Case 1: Truncated Normal Distribution","what":"Grid Testset","title":"IES_Simulation","text":"MEE grid test set.  ASE grid test set.  can see IES performs consistently well MEE, slightly worse ASE. reasonable given nature IES .","code":"ggplot(data = dplyr::filter(result, Measure == \"MEE_grid\"), aes(x = Method, y = Value, color = Method)) +    geom_boxplot() + ggtitle(\"Case1_MEE_Grid\") ggplot(data = dplyr::filter(result, Measure == \"ASE_grid\"), aes(x = Method, y = Value, color = Method)) +    geom_boxplot() + ggtitle(\"Case1_ASE_Grid\")"},{"path":"https://jieyinstat.github.io/dbsubsampling/articles/IES_Simulation.html","id":"case2-truncated-exponential-distribution","dir":"Articles","previous_headings":"Numeric Simulation","what":"Case2: Truncated Exponential Distribution","title":"IES_Simulation","text":"compute simulation result case 2 plot barplots MEE ASE two test datasets based three subsampling methods.","code":"get_combine_result <- function(i) {   data_train <- gene_data(N, rho, lower, upper, sd, \"exp\")   test_distribute <- gene_data(test_distribute_num, rho, lower, upper, sd, \"exp\")   rbind(get_result(\"Unif\", data_train, n, K, h_grid, test_distribute, test_grid),         get_result(\"LowCon\", data_train, n, K, h_grid, test_distribute, test_grid),         get_result(\"IES\", data_train, n, K, h_grid, test_distribute, test_grid)) }  Case2_time_start <- Sys.time() result_case_2 <- parallel::mclapply(1:5, get_combine_result, mc.cores = 5) print(Sys.time() - Case2_time_start) #> Time difference of 39.30968 mins result <- do.call(rbind, result_case_2) %>%    as.data.frame() %>%    dplyr::mutate(dplyr::across(!Method, as.double),          Method = factor(Method)) %>%    tidyr::pivot_longer(!Method, names_to = \"Measure\", values_to = \"Value\")"},{"path":"https://jieyinstat.github.io/dbsubsampling/articles/IES_Simulation.html","id":"distribution-testset-1","dir":"Articles","previous_headings":"Numeric Simulation > Case2: Truncated Exponential Distribution","what":"Distribution Testset","title":"IES_Simulation","text":"MEE distribution test set:  ASE distribution test set:","code":"ggplot(data = dplyr::filter(result, Measure == \"MEE_distribute\"), aes(x = Method, y = Value, color = Method)) +    geom_boxplot() + ggtitle(\"Case2_MEE_Distribute\") ggplot(data = dplyr::filter(result, Measure == \"ASE_distribute\"), aes(x = Method, y = Value, color = Method)) +    geom_boxplot() + ggtitle(\"Case2_ASE_Distribute\")"},{"path":"https://jieyinstat.github.io/dbsubsampling/articles/IES_Simulation.html","id":"grid-testset-1","dir":"Articles","previous_headings":"Numeric Simulation > Case2: Truncated Exponential Distribution","what":"Grid Testset","title":"IES_Simulation","text":"MEE grid test set.  ASE grid test set.  Case2 exponential distribution, IES performs consistently well MEE ASE. implies IES performs better biased distribution?","code":"ggplot(data = dplyr::filter(result, Measure == \"MEE_grid\"), aes(x = Method, y = Value, color = Method)) +    geom_boxplot() + ggtitle(\"Case2_MEE_Grid\") ggplot(data = dplyr::filter(result, Measure == \"ASE_grid\"), aes(x = Method, y = Value, color = Method)) +    geom_boxplot() + ggtitle(\"Case2_ASE_Grid\")"},{"path":[]},{"path":"https://jieyinstat.github.io/dbsubsampling/articles/IES_Simulation.html","id":"description","dir":"Articles","previous_headings":"Real Case","what":"Description","title":"IES_Simulation","text":"use diaomonds data set inggplot2 package. Involving three numeric variables carat, depth table predictors, set price response implement log transform carat price. get four models based full data three subsample methods (set \\(n=5000\\) ) observe estimation component functions. still use five-folds cross validation get optimal bandwidth search space numerical simulation. Hyper-parameter stall set \\(q=16\\). get optimal bandwidth, set handle_outlier=TRUE. ensures boundary predictor training set value, otherwise range application model small, resulting poor results. (numeric simulation, didn’t consider handle outliers)","code":"real_train <- ggplot2::diamonds |>   dplyr::filter(x !=0 & y != 0 & z != 0) |>   dplyr::select(carat, depth, table, y = price) |>   dplyr::mutate(carat = log(carat), y = log(y)) N <- nrow(real_train); n <- 5000; q = 16; K = 5; x_name <- c(\"carat\", \"depth\", \"table\") one_dim_seq <- seq(0.05, 0.95, length.out = 10) h_grid <- expand.grid(one_dim_seq, one_dim_seq, one_dim_seq, KEEP.OUT.ATTRS = FALSE)  index <- list(   Full = 1:N,   Unif = sample(1:N, n),   LowCon = dbsubsampling::LowCon(real_train[,c(\"carat\", \"depth\", \"table\")], n, theta=1),   IES = dbsubsampling::IES(real_train[,c(\"carat\", \"depth\", \"table\")], n, q))  real_cv_time <- Sys.time() h_opt <- purrr::map(index,                      function(.index)                        suppressWarnings(                         get_opt_h(h_grid, real_train[.index,], K,                                    x_name = x_name, y_name = \"y\",                                   handle_outlier = TRUE))) print(Sys.time() - real_cv_time) #> Time difference of 14.3695 mins"},{"path":"https://jieyinstat.github.io/dbsubsampling/articles/IES_Simulation.html","id":"estimate-component-function","dir":"Articles","previous_headings":"Real Case","what":"Estimate component function","title":"IES_Simulation","text":"use gam::predict.Gam function set parameter type = \"terms\" get estimation regression function predictor. obtaining estimate centralize regression function. use two sets testing, one training set test set, consisting grid three variable values. (\\(50 \\times 50 \\times 50\\) points \\([-1.6, 1.6] \\times [43, 79] \\times [43, 95]\\)) Due small sample size subsample, model fitted small scope application, extrapolated values outside scope (use termwise nearest neighbor estimation, fact, replace values outside boundary boundary values). Estimates outside boundary inaccurate without extrapolation, especially Unif LowCon (IES wider boundaries due one-dimensional uniformity). plot estimate three component functions distribution test set. can see LowCon performs worst close non-convergence. Unif also performed poorly, especially border. IES performed best closely full sample.  estimate three component functions grid testset similar performance distribution testset.","code":"get_interval <- function(data, index, x_name) {   x <- data[, x_name]   subdata <- x[index, ]   interval <- apply(subdata, 2, range)   return(interval) }  extrapolation <- function(data, interval, x_name) {   x <- data[, x_name]   for (j in 1:ncol(x)) {     x[,j][x[,j] < interval[1,j]] <- interval[1,j]     x[,j][x[,j] > interval[2,j]] <- interval[2,j]   }   data[, x_name] <- x   return(data) }  model <- purrr::map2(h_opt, index, function(.h, .index) {   opt_formula <- formula(y ~                             lo(carat, span = .h[1], degree = 1) +                             lo(depth, span = .h[2], degree = 1) +                             lo(table, span = .h[3], degree = 1))   gam::gam(opt_formula, data = real_train[.index,]) })  interval <- purrr::map(index, function(.index)                                  get_interval(real_train, .index, x_name))  extrapolation_ori_data <- purrr::map(interval,                                  function(.interval)                                    extrapolation(real_train, .interval, x_name)) predict_ori_data <- purrr::map2(model, extrapolation_ori_data,                                  function(.model, .data)                                    predict.Gam(.model, .data, type = \"terms\"))  real_grid <- expand.grid(carat = seq(-1.6, 1.6, length.out = 50),                          depth = seq(43, 79, length.out = 50),                          table = seq(43, 95, length.out = 50),                          KEEP.OUT.ATTRS = FALSE)  extrapolation_grid_data <- purrr::map(interval,                                  function(.interval)                                    extrapolation(real_grid, .interval, x_name)) predict_grid_data <- purrr::map2(model, extrapolation_grid_data,                                  function(.model, .data)                                    predict.Gam(.model, .data, type = \"terms\")) ori_predict <- predict_ori_data %>%    purrr::map(scale, center = TRUE, scale = FALSE) %>%    purrr::map(as.data.frame) %>%    purrr::map(rename, y_carat = \"lo(carat, span = .h[1], degree = 1)\",                      y_depth = \"lo(depth, span = .h[2], degree = 1)\",                       y_table = \"lo(table, span = .h[3], degree = 1)\") %>%   dplyr::bind_rows(.id = \"Method\") %>%    tibble::remove_rownames() %>%    cbind(rbind(real_train, real_train, real_train, real_train)) %>%    dplyr::rename(x_carat = carat, x_depth = depth, x_table = table) %>%   dplyr::select(-y) %>%    tidyr::pivot_longer(!Method, names_to = c(\".value\", \"Variable\"), names_sep = \"_\")  grid_predict <- predict_grid_data %>%    purrr::map(scale, center = TRUE, scale = FALSE) %>%    purrr::map(as.data.frame) %>%    purrr::map(rename, y_carat = \"lo(carat, span = .h[1], degree = 1)\",                      y_depth = \"lo(depth, span = .h[2], degree = 1)\",                       y_table = \"lo(table, span = .h[3], degree = 1)\") %>%   dplyr::bind_rows(.id = \"Method\") %>%    tibble::remove_rownames() %>%    cbind(rbind(real_grid, real_grid, real_grid, real_grid)) %>%    dplyr::rename(x_carat = carat, x_depth = depth, x_table = table) %>%   tidyr::pivot_longer(!Method, names_to = c(\".value\", \"Variable\"), names_sep = \"_\") ori_predict %>%    ggplot(aes(x = x, y = y, group = Method, color = Method, linetype = Method)) +   geom_line() +   facet_wrap(~Variable, scales = \"free\") +   ggtitle(\"Component function estimation on the original data.\") grid_predict %>%    ggplot(aes(x = x, y = y, group = Method, color = Method, linetype = Method)) +   geom_line() +   facet_wrap(~Variable, scales = \"free\") +   ggtitle(\"Component function estimation on the grid.\")"},{"path":"https://jieyinstat.github.io/dbsubsampling/articles/IES_Simulation.html","id":"compute-measures","dir":"Articles","previous_headings":"Real Case","what":"Compute measures","title":"IES_Simulation","text":"compare MEE ASE grid original data models based different subsample full data. real response grid test set, use estimate obtained model based full data response. Extrapolation carried drawing graphs, also calculating measures, otherwise values MEE ASE extremely large (especially LowCon Unif).  IES performed consistently well MEE. ASE performs better grid test set worse distribution test set (possibly due data leakage). line expectations. reproduced IES simulations , others subject subsequent refinement.","code":"y_ori <- real_train[[\"y\"]] y_grid <- predict.Gam(model[[\"Full\"]], real_grid) predict_extra_ori <- purrr::map2(model, extrapolation_ori_data, predict.Gam) predict_extra_grid <- purrr::map2(model, extrapolation_grid_data, predict.Gam)  extra_measure <- bind_cols(   Measure = c(\"MEE_Ori\", \"ASE_Ori\", \"MEE_Grid\", \"ASE_Grid\"),   dplyr::bind_rows(purrr::map_dbl(predict_extra_ori, mee, y_ori),                    purrr::map_dbl(predict_extra_ori, ase, y_ori),                    purrr::map_dbl(predict_extra_grid, mee, y_grid),                    purrr::map_dbl(predict_extra_grid, ase, y_grid))) %>%   tidyr::pivot_longer(!Measure, names_to = \"Method\", values_to = \"Value\")  extra_measure %>%    ggplot(aes(y = Method, x = Value)) +   geom_bar(stat = \"identity\") +   facet_wrap(~Measure, scales = \"free\")"},{"path":"https://jieyinstat.github.io/dbsubsampling/articles/Subsampling.html","id":"uniform-sampling","dir":"Articles","previous_headings":"","what":"Uniform Sampling","title":"Subsampling","text":"Get random subsample equal probability. can set random seed, random seed valid sampling affect external environment. parameter replace default TURE means sampling replacement, can set FALSE implement sampling without replacement.","code":"N <- 1000 n <- 10 Unif(N = 1000, n = 10) #>  [1] 399 717 678  45 174 855  36 670 353 806 Unif(N = 1000, n = 10, seed = 123, replace = TRUE) #>  [1] 415 463 179 526 195 938 818 118 299 229"},{"path":"https://jieyinstat.github.io/dbsubsampling/articles/Subsampling.html","id":"osmac","dir":"Articles","previous_headings":"","what":"OSMAC","title":"Subsampling","text":"subsampling method based - / L- optimal logistic regression proposed Wang et.al. (2018)1.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/articles/Subsampling.html","id":"a-optimal","dir":"Articles","previous_headings":"OSMAC","what":"A-optimal","title":"Subsampling","text":"-optimal minimise trace covariance matrix parameter estimates. can use unified interface (recommended):","code":"data_binary <- data_binary_class y <- data_binary[[\"y\"]] x <- data_binary[-which(names(data_binary) == \"y\")]  OSMAC(X = x, Y = y, r1 = 100, r2 = 10, method=\"mmse\", seed_1 = 123, seed_2 = 456) #>  [1] 5684 1620 5372 8297 8863 9783 6483 6103 2702 5735 subsampling(y_name = \"y\", data = data_binary, n = 10, pilot_n = 100, method = \"OSMAC_A\",              seed_1 = 123, seed_2 = 456) #>  [1] 5684 1620 5372 8297 8863 9783 6483 6103 2702 5735"},{"path":"https://jieyinstat.github.io/dbsubsampling/articles/Subsampling.html","id":"l-optimal","dir":"Articles","previous_headings":"OSMAC","what":"L-optimal","title":"Subsampling","text":"L-optimal minimise trace covariance matrix linear combination parameter estimates. can use unified interface (recommended): Tips: uniform sampling can use unified interface :","code":"OSMAC(X = x, Y = y, r1 = 100, r2 = 10, method=\"mvc\", seed_1 = 123, seed_2 = 456) #>  [1] 5813 1681 5372 8313 8863 9780 1630 6103 2702 5888 subsampling(y_name = \"y\", data = data_binary, n = 10, pilot_n = 100, method = \"OSMAC_L\",              seed_1 = 123, seed_2 = 456) #>  [1] 5813 1681 5372 8313 8863 9780 1630 6103 2702 5888 subsampling(y_name = \"y\", data = data_binary, n = 10, method = \"Unif\", seed_1 = 123) #>  [1] 4761 6746 9819 2757 5107 9145 9209 2888 6170 2567"},{"path":"https://jieyinstat.github.io/dbsubsampling/articles/Subsampling.html","id":"iboss","dir":"Articles","previous_headings":"","what":"IBOSS","title":"Subsampling","text":"subsampling method based D-optimal linear regression proposed Wang et.al. (2019)2. can use unified interface (recommended):","code":"data_numeric <- data_numeric_regression X <- data_numeric[-which(names(data_numeric) == \"y\")] IBOSS(n = 100, X = X) #>  [1]  183  226  395  419  584  666  711  758 1027 1144 1324 1445 1940 1946 1978 #> [16] 2018 2673 2982 3190 3395 3484 3612 3632 3638 3696 3816 3835 3896 3921 4256 #> [31] 4312 4405 4523 4551 4729 4938 5121 5226 5342 5410 5679 5770 5995 6089 6163 #> [46] 6170 6203 6250 6525 6964 6979 7053 7198 7407 7564 7633 7915 7935 7967 7992 #> [61] 8026 8088 8106 8156 8161 8267 8306 8501 8503 8521 8534 8694 8805 8841 9117 #> [76] 9211 9302 9364 9398 9456 9676 9946 9971 9989 1173 2344 5394 8438 8567 9239 #> [91] 1787 2104 2215 3121 7159 9133 subsampling(y_name = \"y\", data = data_numeric, n = 100, method = \"IBOSS\") #>  [1]  183  226  395  419  584  666  711  758 1027 1144 1324 1445 1940 1946 1978 #> [16] 2018 2673 2982 3190 3395 3484 3612 3632 3638 3696 3816 3835 3896 3921 4256 #> [31] 4312 4405 4523 4551 4729 4938 5121 5226 5342 5410 5679 5770 5995 6089 6163 #> [46] 6170 6203 6250 6525 6964 6979 7053 7198 7407 7564 7633 7915 7935 7967 7992 #> [61] 8026 8088 8106 8156 8161 8267 8306 8501 8503 8521 8534 8694 8805 8841 9117 #> [76] 9211 9302 9364 9398 9456 9676 9946 9971 9989 1173 2344 5394 8438 8567 9239 #> [91] 1787 2104 2215 3121 7159 9133"},{"path":"https://jieyinstat.github.io/dbsubsampling/articles/Subsampling.html","id":"oss","dir":"Articles","previous_headings":"","what":"OSS","title":"Subsampling","text":"subsampling method based Orthogonal Array proposed Wang et.al.(2021)3. can use unified interface (recommended):","code":"OSS(n = 10, X = X) #>  [1] 8841 8961 1902 7512   48 9867 6547 9784 3392 3622 subsampling(y_name = \"y\", data = data_numeric, n = 10, method = \"OSS\") #>  [1] 8841 8961 1902 7512   48 9867 6547 9784 3392 3622"},{"path":"https://jieyinstat.github.io/dbsubsampling/articles/Subsampling.html","id":"lowcon","dir":"Articles","previous_headings":"","what":"LowCon","title":"Subsampling","text":"subsampling method based Space-filling designs proposed Meng et.al.(2021)4. can use unified interface (recommended):","code":"LowCon(X = X, n = 10, theta = 1, seed = 123) #>  [1] 6032 6633 4180 5093 6005 7093 3621 4429 1715 7143 subsampling(y_name = \"y\", data = data_numeric, n = 10, method = \"LowCon\", seed = 123, theta = 1) #>  [1] 6032 6633 4180 5093 6005 7093 3621 4429 1715 7143"},{"path":"https://jieyinstat.github.io/dbsubsampling/articles/Subsampling.html","id":"ies","dir":"Articles","previous_headings":"","what":"IES","title":"Subsampling","text":"subsampling method based Orthogonal Array proposed Zhang et.al.(2024)5. can use unified interface (recommended): ’re working features，subsampling based Support point, DDS, etc.","code":"IES(X = X, n = 10, q = 16, seed = 123) #>  [1] 2876 7890 4440 9400 9813 2499 4939 8165 2224 4628 subsampling(y_name = \"y\", data = data_numeric, n = 10, method = \"IES\", seed = 123, q = 16) #>  [1] 2876 7890 4440 9400 9813 2499 4939 8165 2224 4628"},{"path":"https://jieyinstat.github.io/dbsubsampling/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jie Yin. Author, maintainer.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Yin J (2024). dbsubsampling: Subsampling Methods Based Experimental Design. R package version 0.0.2, https://jieyinstat.github.io/dbsubsampling/, https://github.com/JieYinStat/dbsubsampling.","code":"@Manual{,   title = {dbsubsampling: Subsampling Methods Based on Experimental Design},   author = {Jie Yin},   year = {2024},   note = {R package version 0.0.2, https://jieyinstat.github.io/dbsubsampling/},   url = {https://github.com/JieYinStat/dbsubsampling}, }"},{"path":"https://jieyinstat.github.io/dbsubsampling/index.html","id":"dbsubsampling-","dir":"","previous_headings":"","what":"Subsampling Methods Based on Experimental Design","title":"Subsampling Methods Based on Experimental Design","text":"Providing unified interface IBOSS, Lowcon, OSS popular design-based subsampling methods.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Subsampling Methods Based on Experimental Design","text":"can install development version dbsubsampling GitHub :","code":"# install.packages(\"devtools\") devtools::install_github(\"JieYinStat/dbsubsampling\")"},{"path":"https://jieyinstat.github.io/dbsubsampling/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Subsampling Methods Based on Experimental Design","text":"basic example shows get subsample index, uniform sampling, OSMAC, IBOSS, OSS, LowCon IES: can get detailed examples article column website.","code":"library(dbsubsampling)  data_binary <- data_binary_class  # Uniform sampling subsampling(y_name = \"y\", data = data_binary, n = 10, method = \"Unif\", seed = 123) #>  [1] 2463 2511 8718 2986 1842 9334 3371 4761 6746 9819  # OSMAC-A subsampling(y_name = \"y\", data = data_binary, n = 10, pilot_n = 100, method = \"OSMAC_A\",              seed_1 = 123, seed_2 = 456) #>  [1] 5684 1620 5372 8297 8863 9783 6483 6103 2702 5735  # OSMAC-L subsampling(y_name = \"y\", data = data_binary, n = 10, pilot_n = 100, method = \"OSMAC_L\",             seed_1 = 123, seed_2 = 456) #>  [1] 5813 1681 5372 8313 8863 9780 1630 6103 2702 5888  # IBOSS data_numeric <- data_numeric_regression subsampling(y_name = \"y\", data = data_numeric, n = 100, method = \"IBOSS\") #>  [1]  183  226  395  419  584  666  711  758 1027 1144 1324 1445 1940 1946 1978 #> [16] 2018 2673 2982 3190 3395 3484 3612 3632 3638 3696 3816 3835 3896 3921 4256 #> [31] 4312 4405 4523 4551 4729 4938 5121 5226 5342 5410 5679 5770 5995 6089 6163 #> [46] 6170 6203 6250 6525 6964 6979 7053 7198 7407 7564 7633 7915 7935 7967 7992 #> [61] 8026 8088 8106 8156 8161 8267 8306 8501 8503 8521 8534 8694 8805 8841 9117 #> [76] 9211 9302 9364 9398 9456 9676 9946 9971 9989 1173 2344 5394 8438 8567 9239 #> [91] 1787 2104 2215 3121 7159 9133  # OSS subsampling(y_name = \"y\", data = data_numeric, n = 30, method = \"OSS\") #>  [1] 8841 8961 1902 7512   48 9867 6547 9784 3392 3622 5780 6594 1890 1850 8335 #> [16] 1254 6204 1257 4611 3831 4782 4919 1579 3404  718 7189 2060 4899  590 1800  # LowCon subsampling(y_name = \"y\", data = data_numeric, n = 10, method = \"LowCon\", seed = 123, theta = 1) #>  [1] 6032 6633 4180 5093 6005 7093 3621 4429 1715 7143  # IES subsampling(y_name = \"y\", data = data_numeric, n = 10, method = \"IES\", seed = 123, q = 16) #>  [1] 2876 7890 4440 9400 9813 2499 4939 8165 2224 4628"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/ComputeLoss.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute loss function for OSS — ComputeLoss","title":"Compute loss function for OSS — ComputeLoss","text":"Compute loss function OSS","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/ComputeLoss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute loss function for OSS — ComputeLoss","text":"","code":"ComputeLoss(candi, last_index, X, norm)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/ComputeLoss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute loss function for OSS — ComputeLoss","text":"candi index candidate set. last_index index seleted point last iteration. X whole data. norm Norm whole data.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/ComputeLoss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute loss function for OSS — ComputeLoss","text":"Loss every point candidate set.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/IBOSS.html","id":null,"dir":"Reference","previous_headings":"","what":"Information-Based Optimal Subdata Selection for Big Data Linear Regression (IBOSS, Rcpp-c++-style by Wang) — IBOSS","title":"Information-Based Optimal Subdata Selection for Big Data Linear Regression (IBOSS, Rcpp-c++-style by Wang) — IBOSS","text":"subsampling method based D-optiaml criterion inspired optimal experimental design used linear regression.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/IBOSS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Information-Based Optimal Subdata Selection for Big Data Linear Regression (IBOSS, Rcpp-c++-style by Wang) — IBOSS","text":"","code":"IBOSS(n, X)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/IBOSS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Information-Based Optimal Subdata Selection for Big Data Linear Regression (IBOSS, Rcpp-c++-style by Wang) — IBOSS","text":"n Subsample size. X data.frame matrix consists explanatory variables.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/IBOSS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Information-Based Optimal Subdata Selection for Big Data Linear Regression (IBOSS, Rcpp-c++-style by Wang) — IBOSS","text":"Subsample index.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/IBOSS.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Information-Based Optimal Subdata Selection for Big Data Linear Regression (IBOSS, Rcpp-c++-style by Wang) — IBOSS","text":"HaiYing Wang, Min Yang & John Stufken (2019) Information-Based Optimal Subdata Selection Big Data Linear Regression, Journal American Statistical Association, 114:525, 393-405, https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1408468, https://github.com/Ossifragus/IBOSS.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/IBOSS.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Information-Based Optimal Subdata Selection for Big Data Linear Regression (IBOSS, Rcpp-c++-style by Wang) — IBOSS","text":"","code":"data <- data_numeric_regression X <- data[-which(names(data) == \"y\")] IBOSS(n = 100, X = X) #>  [1]  183  226  395  419  584  666  711  758 1027 1144 1324 1445 1940 1946 1978 #> [16] 2018 2673 2982 3190 3395 3484 3612 3632 3638 3696 3816 3835 3896 3921 4256 #> [31] 4312 4405 4523 4551 4729 4938 5121 5226 5342 5410 5679 5770 5995 6089 6163 #> [46] 6170 6203 6250 6525 6964 6979 7053 7198 7407 7564 7633 7915 7935 7967 7992 #> [61] 8026 8088 8106 8156 8161 8267 8306 8501 8503 8521 8534 8694 8805 8841 9117 #> [76] 9211 9302 9364 9398 9456 9676 9946 9971 9989 1173 2344 5394 8438 8567 9239 #> [91] 1787 2104 2215 3121 7159 9133"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/IES.html","id":null,"dir":"Reference","previous_headings":"","what":"Independence-Encouraging Subsampling for Nonparametric Additive Models (IES, Proposed by Zhang et.al. (2024)) — IES","title":"Independence-Encouraging Subsampling for Nonparametric Additive Models (IES, Proposed by Zhang et.al. (2024)) — IES","text":"subsampling method nonparameter additive model based Orthogonal Array.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/IES.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Independence-Encouraging Subsampling for Nonparametric Additive Models (IES, Proposed by Zhang et.al. (2024)) — IES","text":"","code":"IES(X, n, q = 16, seed = NULL)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/IES.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Independence-Encouraging Subsampling for Nonparametric Additive Models (IES, Proposed by Zhang et.al. (2024)) — IES","text":"X data.frame matrix consists explanatory variables. n Subsample size. q Hyperparamter divide axes. Default 16. seed Random seed sampling.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/IES.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Independence-Encouraging Subsampling for Nonparametric Additive Models (IES, Proposed by Zhang et.al. (2024)) — IES","text":"Subsample index.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/IES.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Independence-Encouraging Subsampling for Nonparametric Additive Models (IES, Proposed by Zhang et.al. (2024)) — IES","text":"Yi Zhang, Lin Wang, Xiaoke Zhang & HaiYing Wang (2024) Independence-Encouraging Subsampling Nonparametric Additive Models, Journal Computational Graphical Statistics, https://www.tandfonline.com/doi/full/10.1080/10618600.2024.2326136.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/IES.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Independence-Encouraging Subsampling for Nonparametric Additive Models (IES, Proposed by Zhang et.al. (2024)) — IES","text":"","code":"data <- data_numeric_regression X <- data[-which(names(data) == \"y\")] IES(X, n = 100, q = 16, seed = NULL) #>   [1]  808 8300 6073 1714  718 2499 4778 2224 7041 7584 7188 2292 1364 8521 5526 #>  [16] 4617 2774 2202 6885 8722  651 7449 6780 4099 8998 7949 6886 8770 7059 4834 #>  [31] 1168 7832 7852 6915 3062 8156 4638 9810 4014 5199 6228  158  450 3991 8818 #>  [46] 8653  955 8908 8783 3242 4526   34  564 5226 2611 1703 5107 8898 1204 1686 #>  [61] 7890  611 5995 2237 9138 9007 7600 6736 6203  309 3948 4310 8805 9649 3874 #>  [76] 5848 7325 2588 5605 6170 6668  260 2944  284 5325 7504 1950 7472 6087 2556 #>  [91] 8861 5860 8841 4986 6600 1844 4864 4072 2723 5362"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/L2norm.html","id":null,"dir":"Reference","previous_headings":"","what":"Get L2 norm — L2norm","title":"Get L2 norm — L2norm","text":"Get L2 norm matrix data frame.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/L2norm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get L2 norm — L2norm","text":"","code":"L2norm(X)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/L2norm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get L2 norm — L2norm","text":"X matrix data.frame.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/L2norm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get L2 norm — L2norm","text":"L2 norm X(every row).","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/LowCon.html","id":null,"dir":"Reference","previous_headings":"","what":"LowCon: A Design-based Subsampling Approach in a Misspecified Linear Model — LowCon","title":"LowCon: A Design-based Subsampling Approach in a Misspecified Linear Model — LowCon","text":"subsampling method based space-filling design misspecified linear model proposed Meng et.al. (2021).","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/LowCon.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"LowCon: A Design-based Subsampling Approach in a Misspecified Linear Model — LowCon","text":"","code":"LowCon(X, n, theta = 1, seed = NULL)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/LowCon.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"LowCon: A Design-based Subsampling Approach in a Misspecified Linear Model — LowCon","text":"X data.frame matrix explanatory variables. n Subsample size. theta Percentage data shrinkage. Default 1. seed Random seed sampling.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/LowCon.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"LowCon: A Design-based Subsampling Approach in a Misspecified Linear Model — LowCon","text":"Subsample index.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/LowCon.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"LowCon: A Design-based Subsampling Approach in a Misspecified Linear Model — LowCon","text":"Cheng Meng, Rui Xie, Abhyuday Mandal, Xinlian Zhang, Wenxuan Zhong & Ping Ma (2021) LowCon: Design-based Subsampling Approach Misspecified Linear Model, Journal Computational Graphical Statistics, 30:3, 694-708, https://www.tandfonline.com/doi/full/10.1080/10618600.2020.1844215.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/LowCon.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"LowCon: A Design-based Subsampling Approach in a Misspecified Linear Model — LowCon","text":"","code":"data <- data_numeric_regression X <- data[-which(names(data) == \"y\")] LowCon(X, n = 100, theta = 1, seed = NULL) #>   [1] 6399 6151 3629 2706 6933 9759 6895 1745 4964  841 6774 5332 2057 6480 1326 #>  [16] 9696 6384 2217  286 1637 1036 6191 5382 6020 5118   31 1249 8019 4654 8860 #>  [31] 3286 3180 1873  281 5862 4884 2744 4668 2151 8618 2245 3131  200 7500 4014 #>  [46] 3426 7048 9750 7930 7069 9472 4723 7851 1502 2500 1567 6123 9375  550 6609 #>  [61] 7930 3460 3351 3861 1818 4506 7153  855 8272 3318 2254  830 9056 2847 8424 #>  [76] 1207 1155 1297 8633 3396 4140 2186 8542 4441 3153 3923 1546 4729 6818 2189 #>  [91] 6307 8679 2881 5393  339  239 4579 3499 4709 7535"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/OSMAC.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Subsampling for Large Sample Logistic Regression(OSMAC) — OSMAC","title":"Optimal Subsampling for Large Sample Logistic Regression(OSMAC) — OSMAC","text":"subsampling method based - / L- optimal logistic regression proposed Wang et.al. (2018).","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/OSMAC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Subsampling for Large Sample Logistic Regression(OSMAC) — OSMAC","text":"","code":"OSMAC(X, Y, r1, r2, method = c(\"mmse\", \"mvc\"), seed_1 = NULL, seed_2 = NULL)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/OSMAC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Subsampling for Large Sample Logistic Regression(OSMAC) — OSMAC","text":"X data.frame matrix explanatory variables. Y numeric vector. Response variable. r1 Sample size pilot sample. r2 Subsample size. method Sampling methods: mmse: -optimal. mvc: L-optimal. seed_1 Random seed first stage sampling. seed_2 Random seed second stage sampling.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/OSMAC.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Subsampling for Large Sample Logistic Regression(OSMAC) — OSMAC","text":"numeric vector length r2 represent subsample index.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/OSMAC.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Subsampling for Large Sample Logistic Regression(OSMAC) — OSMAC","text":"HaiYing Wang, Rong Zhu Ping Ma (2018) Optimal Subsampling Large Sample Logistic Regression, Journal American Statistical Association, 113:522, 829-844, https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1292914, https://github.com/Ossifragus/OSMAC.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/OSMAC.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Subsampling for Large Sample Logistic Regression(OSMAC) — OSMAC","text":"","code":"data <- data_binary_class y <- data[[\"y\"]] x <- data[-which(names(data) == \"y\")]  OSMAC(X = x, Y = y, r1 = 100, r2 = 5, method=\"mmse\", seed_1 = 123, seed_2 = 456) #> [1] 5684 1620 5372 8297 8863 OSMAC(X = x, Y = y, r1 = 100, r2 = 5, method=\"mvc\", seed_1 = 123, seed_2 = 456) #> [1] 5813 1681 5372 8313 8863"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/OSS.html","id":null,"dir":"Reference","previous_headings":"","what":"Orthogonal subsampling for big data linear regression (OSS, Rcpp-version by the package itself) — OSS","title":"Orthogonal subsampling for big data linear regression (OSS, Rcpp-version by the package itself) — OSS","text":"subsampling method based orthogonal array linear model.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/OSS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Orthogonal subsampling for big data linear regression (OSS, Rcpp-version by the package itself) — OSS","text":"","code":"OSS(n, X)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/OSS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Orthogonal subsampling for big data linear regression (OSS, Rcpp-version by the package itself) — OSS","text":"n Subsample size. X matrix data frame.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/OSS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Orthogonal subsampling for big data linear regression (OSS, Rcpp-version by the package itself) — OSS","text":"Subsample index.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/OSS.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Orthogonal subsampling for big data linear regression (OSS, Rcpp-version by the package itself) — OSS","text":"Lin Wang, Jake Elmstedt, Weng Kee Wong & Hongquan Xu (2021) Orthogonal subsampling big data linear regression, Annals Applied Statistics, 15(3), 1273-1290, https://projecteuclid.org/journals/annals--applied-statistics/volume-15/issue-3/Orthogonal-subsampling--big-data-linear-regression/10.1214/21-AOAS1462.short?tab=ArticleLink.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/OSS.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Orthogonal subsampling for big data linear regression (OSS, Rcpp-version by the package itself) — OSS","text":"","code":"data_numeric_regression[\"y\"] <- NULL X <- as.matrix(data_numeric_regression) OSS(100, X) #>   [1] 8841 8961 1902 7512   48 9867 6547 9784 3392 3622 5780 6594 1890 1850 8335 #>  [16] 1254 6204 1257 4611 3831 4782 4919 1579 3404  718 7189 2060 4899  590 1800 #>  [31] 1195 3763 4033  607  714 8515 9026 4449 1921 6102 2550 8666 7403 1217 2633 #>  [46] 6481 5047  901 1738 9774 5242 1293 4981 5754 9770 7773 3075 9778 5650 1914 #>  [61] 7010 1605 6000 4995 6115  131 1594 7895 5217 2345 6992 9790 4461 4135 4737 #>  [76] 8989  129 8542 3067 3116 5266 3156 1365 8982 6922 5105 1366 5136 3532  253 #>  [91] 5693 8559 6242 2431  999 7480 5310  224 5662 1280"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/Unif.html","id":null,"dir":"Reference","previous_headings":"","what":"Uniform sampling. — Unif","title":"Uniform sampling. — Unif","text":"Random sampling equal probability.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/Unif.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Uniform sampling. — Unif","text":"","code":"Unif(N, n, seed = NULL, replace = TRUE)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/Unif.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Uniform sampling. — Unif","text":"N Total sample size. n Subsample size. seed Random seed integer (default NULL). random seed valid sampling affect external environment replace boolean. TRUE (default): Sampling replace. FALSE: Sampling without replace","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/Unif.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Uniform sampling. — Unif","text":"numeric vector length n represent subsample index.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/Unif.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Uniform sampling. — Unif","text":"","code":"N <- 1000 n <- 10 Unif(N = 1000, n = 10) #>  [1] 878 704 953 314 191 418 848 329 668 924 Unif(N = 1000, n = 10) #>  [1] 305 230 377 348 738 793 634 259 314 488 Unif(N = 1000, n = 10) != Unif(N = 1000, n = 10) #>  [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE  Unif(N = 1000, n = 10, seed = 1) #>  [1] 836 679 129 930 509 471 299 270 978 187 Unif(N = 1000, n = 10, seed = 123) #>  [1] 415 463 179 526 195 938 818 118 299 229  Unif(N = 1000, n = 10, seed = 123, replace = TRUE) #>  [1] 415 463 179 526 195 938 818 118 299 229 Unif(N = 1000, n = 10, seed = 123, replace = FALSE) #>  [1] 415 463 179 526 195 938 818 118 299 229"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/armaComputeLoss.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute loss function for OSS (RcppArmadillo-version) — armaComputeLoss","title":"Compute loss function for OSS (RcppArmadillo-version) — armaComputeLoss","text":"Compute loss function OSS (RcppArmadillo-version)","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/armaComputeLoss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute loss function for OSS (RcppArmadillo-version) — armaComputeLoss","text":"","code":"armaComputeLoss(X, xa, y, ya, tPow)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/armaComputeLoss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute loss function for OSS (RcppArmadillo-version) — armaComputeLoss","text":"X Matrix candidate set. xa Norm candidate set. y vector. point selected last iteration. ya Norm y. tPow power loss function.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/armaComputeLoss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute loss function for OSS (RcppArmadillo-version) — armaComputeLoss","text":"Loss candidate set.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/armaIES.html","id":null,"dir":"Reference","previous_headings":"","what":"IES Core Code Using RcppArmadillo. — armaIES","title":"IES Core Code Using RcppArmadillo. — armaIES","text":"IES Core Code Using RcppArmadillo.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/armaIES.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"IES Core Code Using RcppArmadillo. — armaIES","text":"","code":"armaIES(X, n, q)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/armaIES.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"IES Core Code Using RcppArmadillo. — armaIES","text":"X data.frame matrix consists explanatory variables. n Subsample size. q Hyperparamter divide axes.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/armaIES_compare.html","id":null,"dir":"Reference","previous_headings":"","what":"IES C++-Version for Benchmarking (C++ Core Code) — armaIES_compare","title":"IES C++-Version for Benchmarking (C++ Core Code) — armaIES_compare","text":"randomness, parts need randomly selected selected first indexed.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/armaIES_compare.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"IES C++-Version for Benchmarking (C++ Core Code) — armaIES_compare","text":"","code":"armaIES_compare(X, n, q)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/armaIES_compare.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"IES C++-Version for Benchmarking (C++ Core Code) — armaIES_compare","text":"X data.frame matrix consists explanatory variables. n Subsample size. q Hyperparamter divide axes.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/armaOSS.html","id":null,"dir":"Reference","previous_headings":"","what":"OSS RcppArmadillo-version by Zhu (myArma_OSS core code) — armaOSS","title":"OSS RcppArmadillo-version by Zhu (myArma_OSS core code) — armaOSS","text":"OSS RcppArmadillo-version Zhu (myArma_OSS core code)","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/armaOSS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"OSS RcppArmadillo-version by Zhu (myArma_OSS core code) — armaOSS","text":"","code":"armaOSS(x, k, tPow = 2)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/armaOSS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"OSS RcppArmadillo-version by Zhu (myArma_OSS core code) — armaOSS","text":"x matrix. k Subsample size. tPow power loss function.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/armaOSS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"OSS RcppArmadillo-version by Zhu (myArma_OSS core code) — armaOSS","text":"Subsample index.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/armaScaleMatrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Scale a matrix (RcppArmadillo-version) — armaScaleMatrix","title":"Scale a matrix (RcppArmadillo-version) — armaScaleMatrix","text":"Scale matrix (RcppArmadillo-version)","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/armaScaleMatrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scale a matrix (RcppArmadillo-version) — armaScaleMatrix","text":"","code":"armaScaleMatrix(X)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/armaScaleMatrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scale a matrix (RcppArmadillo-version) — armaScaleMatrix","text":"X matrix.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/armaScaleMatrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Scale a matrix (RcppArmadillo-version) — armaScaleMatrix","text":"Scaled matrix.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/armabottom_k.html","id":null,"dir":"Reference","previous_headings":"","what":"Find t smallest index of a vector (RcppArmadillo-version) — armabottom_k","title":"Find t smallest index of a vector (RcppArmadillo-version) — armabottom_k","text":"Find t smallest index vector (RcppArmadillo-version)","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/armabottom_k.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find t smallest index of a vector (RcppArmadillo-version) — armabottom_k","text":"","code":"armabottom_k(x, k)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/armabottom_k.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find t smallest index of a vector (RcppArmadillo-version) — armabottom_k","text":"x vector. k int.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/armabottom_k.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find t smallest index of a vector (RcppArmadillo-version) — armabottom_k","text":"index t smallest element vector.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/armarcppIBOSS.html","id":null,"dir":"Reference","previous_headings":"","what":"IBOSS with RcppArmadillo by the package itself (myArma_IBOSS core c++ code) — armarcppIBOSS","title":"IBOSS with RcppArmadillo by the package itself (myArma_IBOSS core c++ code) — armarcppIBOSS","text":"IBOSS RcppArmadillo package (myArma_IBOSS core c++ code)","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/armarcppIBOSS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"IBOSS with RcppArmadillo by the package itself (myArma_IBOSS core c++ code) — armarcppIBOSS","text":"","code":"armarcppIBOSS(X, n)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/armarcppIBOSS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"IBOSS with RcppArmadillo by the package itself (myArma_IBOSS core c++ code) — armarcppIBOSS","text":"X data.frame matrix consists explanatory variables. n Subsample size.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/armarcppIBOSS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"IBOSS with RcppArmadillo by the package itself (myArma_IBOSS core c++ code) — armarcppIBOSS","text":"Subsample index.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/bottom_t_index.html","id":null,"dir":"Reference","previous_headings":"","what":"Find t smallest index of a vector — bottom_t_index","title":"Find t smallest index of a vector — bottom_t_index","text":"Find t smallest index vector","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/bottom_t_index.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find t smallest index of a vector — bottom_t_index","text":"","code":"bottom_t_index(loss, t)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/bottom_t_index.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find t smallest index of a vector — bottom_t_index","text":"loss vector. t int.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/bottom_t_index.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find t smallest index of a vector — bottom_t_index","text":"index t smallest element vector.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/c_IES_compare.html","id":null,"dir":"Reference","previous_headings":"","what":"IES C++-Version for Benchmarking (R-Wrap Code) — c_IES_compare","title":"IES C++-Version for Benchmarking (R-Wrap Code) — c_IES_compare","text":"randomness, parts need randomly selected selected first indexed.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/c_IES_compare.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"IES C++-Version for Benchmarking (R-Wrap Code) — c_IES_compare","text":"","code":"c_IES_compare(X, n, q)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/c_IES_compare.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"IES C++-Version for Benchmarking (R-Wrap Code) — c_IES_compare","text":"X X data.frame matrix consists explanatory variables. n Subsample size. q Hyperparamter divide axes.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/data_IES_Case_1_Train.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulation datasets of IES Case1 — data_IES_Case_1_Train","title":"Simulation datasets of IES Case1 — data_IES_Case_1_Train","text":"data.frame numeric response real overall mean three predictors generated truncated multivariate normal distribution.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/data_IES_Case_1_Train.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulation datasets of IES Case1 — data_IES_Case_1_Train","text":"","code":"data_IES_Case_1_Train"},{"path":[]},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/data_IES_Case_1_Train.html","id":"data-ies-case-train","dir":"Reference","previous_headings":"","what":"data_IES_Case_1_Train","title":"Simulation datasets of IES Case1 — data_IES_Case_1_Train","text":"data.frame 10000 rows 5 columns. X1-X3 Explanatory variables generated truncated multivariate normal distribution. m Real overall average. y Response variable.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/data_IES_Case_1_Train.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulation datasets of IES Case1 — data_IES_Case_1_Train","text":"three predictors generated truncated multivariate normal distribution \\(TN(0, \\Sigma, -2, 2)\\) , mean zero covariance matrix \\(\\Sigma=(0.3^{\\mathbb{1}(\\ne j)})\\) , predictor lies \\([-2, 2]\\). response generated \\(y = m(x) + \\epsilon\\),  $$\\begin{aligned} m(x) &= m_1(x_1) + m_2(x_2) + m_3(x_3) \\\\                            &= \\frac{8}{4 + x_1} + \\frac{\\exp(3-x^2_2)}{4} + 1.5\\sin(\\frac{\\pi}{2}x_3),        \\end{aligned}$$ \\(\\epsilon\\) follows \\(N(0, \\sigma^2)\\), variance \\(\\sigma^2=0.25\\). generated predictors using rtmvnorm function package TruncatedNormal.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/data_IES_Case_2_Train.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulation datasets of IES Case2 — data_IES_Case_2_Train","title":"Simulation datasets of IES Case2 — data_IES_Case_2_Train","text":"data.frame numeric response real overall mean three predictors generated truncated multivariate exponential distribution.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/data_IES_Case_2_Train.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulation datasets of IES Case2 — data_IES_Case_2_Train","text":"","code":"data_IES_Case_2_Train"},{"path":[]},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/data_IES_Case_2_Train.html","id":"data-ies-case-train","dir":"Reference","previous_headings":"","what":"data_IES_Case_2_Train","title":"Simulation datasets of IES Case2 — data_IES_Case_2_Train","text":"data.frame 10000 rows 5 columns. X1-X3 Explanatory variables generated truncated multivariate exponential distribution. m Real overall average. y Response variable.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/data_IES_Case_2_Train.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulation datasets of IES Case2 — data_IES_Case_2_Train","text":"three predictors generated truncated multivariate exponential distribution covariance matrix \\(\\Sigma=(0.3^{\\mathbb{1}(\\ne j)})\\). marginal distribution exponential distribution rate 1, truncated 4 translated \\([-2, 2]\\). response generated \\(y = m(x) + \\epsilon\\),  $$\\begin{aligned} m(x) &= m_1(x_1) + m_2(x_2) + m_3(x_3) \\\\                            &= \\frac{8}{4 + x_1} + \\frac{\\exp(3-x^2_2)}{4} + 1.5\\sin(\\frac{\\pi}{2}x_3),        \\end{aligned}$$ \\(\\epsilon\\) follows \\(N(0, \\sigma^2)\\), variance \\(\\sigma^2=0.25\\). generated predictors using ellipCopula rCopula function package copula.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/data_binary_class.html","id":null,"dir":"Reference","previous_headings":"","what":"An artificial data set for logistic regression — data_binary_class","title":"An artificial data set for logistic regression — data_binary_class","text":"data.frame binary response explanatory variables generated multivariate normal distribution \\(N(\\boldsymbol{0}, \\boldsymbol{\\Sigma})\\), \\(\\boldsymbol{\\Sigma}_{ij}=0.5^{(\\neq j)}, ,j=1,\\dots,7.\\) probability class label 1 point \\(\\boldsymbol{x}\\) \\(h(\\boldsymbol{x}, \\boldsymbol{\\beta}) = 1/(1 + \\exp(−\\boldsymbol{x}^{T}\\boldsymbol{\\beta}))\\), \\(\\boldsymbol{\\beta}\\) 7 \\(\\times\\) 1 vector 0.5.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/data_binary_class.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"An artificial data set for logistic regression — data_binary_class","text":"","code":"data_binary_class"},{"path":[]},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/data_binary_class.html","id":"data-binary-class","dir":"Reference","previous_headings":"","what":"data_binary_class","title":"An artificial data set for logistic regression — data_binary_class","text":"data frame 10000 rows 7 columns: X1-X6 explanatory variables generated multivariate normal distribution y response variable","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/data_numeric_regression.html","id":null,"dir":"Reference","previous_headings":"","what":"An artificial data set for linear regression. — data_numeric_regression","title":"An artificial data set for linear regression. — data_numeric_regression","text":"data.frame numeric response explanatory variables simulated real life borehole example flow rate water borehole upper aquifer lower aquifer separated impermeable rock layer.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/data_numeric_regression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"An artificial data set for linear regression. — data_numeric_regression","text":"","code":"data_numeric_regression"},{"path":[]},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/data_numeric_regression.html","id":"data-numeric-regression","dir":"Reference","previous_headings":"","what":"data_numeric_regression","title":"An artificial data set for linear regression. — data_numeric_regression","text":"data frame 10000 rows 9 columns: \\(\\mathcal{Y}\\) response variable, flow rate borehole. \\(r_{\\mathrm{w}}\\) radius borehole. \\(r\\) radius influence. \\(T_{\\mathrm{u}}\\) transmissivity upper aquifer. \\(T_1\\) transmissivity lower aquifer. \\(H_{\\mathrm{u}}\\) potentiometric head upper aquifer. \\(H_1\\) potentiometric head lower aquifer. \\(L\\) length borehole. \\(K_{\\mathrm{w}}\\) hydraulic conductivity borehole.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/data_numeric_regression.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"An artificial data set for linear regression. — data_numeric_regression","text":"response variable \\(\\mathcal{Y}\\), flow rate borehole \\(m^3 / yr\\), determined complex nonlinear function follows, $$\\mathcal{Y}=\\frac{2 \\pi T_{\\mathrm{u}}\\left(H_{\\mathrm{u}}-H_{\\mathrm{l}}\\right)}{\\ln \\left(r / r_{\\mathrm{w}}\\right)\\left[1+\\frac{2 L T_{\\mathrm{u}}}{\\ln \\left(r / r_{\\mathrm{w}}\\right) r_{\\mathrm{w}}^2 K_{\\mathrm{w}}^2}+\\frac{T_{\\mathrm{u}}}{T_1}\\right]},$$ 8 input variables usual input ranges listed follows: \\(r_{\\mathrm{w}} \\[0.05,0.15]\\) means radius borehole (\\(m\\)); \\(r \\[100,50000]\\) means radius influence (\\(m\\)); \\(T_{\\mathrm{u}} \\[63070,115600]\\) means transmissivity upper aquifer(\\(\\left(\\mathrm{m}^2 / \\mathrm{yr}\\right)\\)); \\(T_1 \\[63.1,116]\\) means transmissivity lower aquifer(\\(\\left(m^2 / y r\\right)\\)); \\(H_{\\mathrm{u}} \\[990,1110]\\) means potentiometric head upper aquifer(\\(m\\)); \\(H_1 \\[700,820]\\) means potentiometric head lower aquifer (\\(m\\)); \\(L \\[1120,1680]\\) means length borehole (\\(m\\)); \\(K_{\\mathrm{w}} \\[9855,12045]\\) means hydraulic conductivity borehole (\\(m / y r\\)). distribution \\(r_{\\mathrm{w}}\\) normal distribution\\(\\mathcal{N}\\left(0.10,0.0161812^2\\right)\\), distribution \\(r\\) lognormal distribution \\(\\operatorname{Lognormal}\\left(7.71,1.0056^2\\right)\\), distributions variables continuous uniform distribution corresponding domains.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/dbsubsampling-package.html","id":null,"dir":"Reference","previous_headings":"","what":"dbsubsampling: Subsampling Methods Based on Experimental Design — dbsubsampling-package","title":"dbsubsampling: Subsampling Methods Based on Experimental Design — dbsubsampling-package","text":"collection design-based subsampling methods inspired optimal design, space-filling design, orthogonal array, etc. Provides unified interface IBOSS, Lowcon, OSS popular methods.","code":""},{"path":[]},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/dbsubsampling-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"dbsubsampling: Subsampling Methods Based on Experimental Design — dbsubsampling-package","text":"Maintainer: Jie Yin yjabcdhot@hotmail.com","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/getIdxR_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Get subsample index of other column(except the first column) (IBOSS core code, Rcpp-C++-style by Wang) — getIdxR_cpp","title":"Get subsample index of other column(except the first column) (IBOSS core code, Rcpp-C++-style by Wang) — getIdxR_cpp","text":"Get subsample index column(except first column) (IBOSS core code, Rcpp-C++-style Wang)","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/getIdxR_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get subsample index of other column(except the first column) (IBOSS core code, Rcpp-C++-style by Wang) — getIdxR_cpp","text":"","code":"getIdxR_cpp(r, z, rdel)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/getIdxR_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get subsample index of other column(except the first column) (IBOSS core code, Rcpp-C++-style by Wang) — getIdxR_cpp","text":"r Subsample size column. z numeric vector. column. rdel Subsample index first column.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/getIdxR_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get subsample index of other column(except the first column) (IBOSS core code, Rcpp-C++-style by Wang) — getIdxR_cpp","text":"Subsample index column.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/getIdx_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Get subsample index of the first column (IBOSS core code, Rcpp-C++-style by Wang) — getIdx_cpp","title":"Get subsample index of the first column (IBOSS core code, Rcpp-C++-style by Wang) — getIdx_cpp","text":"Get subsample index first column (IBOSS core code, Rcpp-C++-style Wang)","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/getIdx_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get subsample index of the first column (IBOSS core code, Rcpp-C++-style by Wang) — getIdx_cpp","text":"","code":"getIdx_cpp(r, z)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/getIdx_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get subsample index of the first column (IBOSS core code, Rcpp-C++-style by Wang) — getIdx_cpp","text":"r Subsample size first column. z numeric vector. first column.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/getIdx_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get subsample index of the first column (IBOSS core code, Rcpp-C++-style by Wang) — getIdx_cpp","text":"Subsample index first column.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/get_Logistic_MLE.html","id":null,"dir":"Reference","previous_headings":"","what":"MLE for Logistic regression — get_Logistic_MLE","title":"MLE for Logistic regression — get_Logistic_MLE","text":"Maximum likelihood estimation logistic regression.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/get_Logistic_MLE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MLE for Logistic regression — get_Logistic_MLE","text":"","code":"get_Logistic_MLE(x, y, w)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/get_Logistic_MLE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MLE for Logistic regression — get_Logistic_MLE","text":"x matrix explanatory variables. y numeric vector. Response variable. w numeric vector. weight sample.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/get_Logistic_MLE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MLE for Logistic regression — get_Logistic_MLE","text":"list. par : Parameter estimation. message : Message iteration. iter : Iteration times.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/myArma_IBOSS.html","id":null,"dir":"Reference","previous_headings":"","what":"IBOSS with RcppArmadillo-r-style by the package itself. — myArma_IBOSS","title":"IBOSS with RcppArmadillo-r-style by the package itself. — myArma_IBOSS","text":"IBOSS RcppArmadillo-r-style package .","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/myArma_IBOSS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"IBOSS with RcppArmadillo-r-style by the package itself. — myArma_IBOSS","text":"","code":"myArma_IBOSS(n, X)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/myArma_IBOSS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"IBOSS with RcppArmadillo-r-style by the package itself. — myArma_IBOSS","text":"n Subsample size. X data.frame matrix consists explanatory variables.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/myArma_IBOSS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"IBOSS with RcppArmadillo-r-style by the package itself. — myArma_IBOSS","text":"Subsample index.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/myArma_OSS.html","id":null,"dir":"Reference","previous_headings":"","what":"OSS (RcppArmadillo-version by Zhu) — myArma_OSS","title":"OSS (RcppArmadillo-version by Zhu) — myArma_OSS","text":"OSS (RcppArmadillo-version Zhu)","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/myArma_OSS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"OSS (RcppArmadillo-version by Zhu) — myArma_OSS","text":"","code":"myArma_OSS(n, X)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/myArma_OSS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"OSS (RcppArmadillo-version by Zhu) — myArma_OSS","text":"n Subsample size. X matrix.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/myArma_OSS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"OSS (RcppArmadillo-version by Zhu) — myArma_OSS","text":"Subsample index.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/myR_IBOSS.html","id":null,"dir":"Reference","previous_headings":"","what":"IBOSS with base R by the package itself. — myR_IBOSS","title":"IBOSS with base R by the package itself. — myR_IBOSS","text":"IBOSS base R package .","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/myR_IBOSS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"IBOSS with base R by the package itself. — myR_IBOSS","text":"","code":"myR_IBOSS(n, X)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/myR_IBOSS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"IBOSS with base R by the package itself. — myR_IBOSS","text":"n Subsample size. X data.frame matrix consists explanatory variables.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/myR_IBOSS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"IBOSS with base R by the package itself. — myR_IBOSS","text":"Subsample index.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/myR_OSS.html","id":null,"dir":"Reference","previous_headings":"","what":"OSS with base R by the package itself. — myR_OSS","title":"OSS with base R by the package itself. — myR_OSS","text":"OSS base R package .","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/myR_OSS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"OSS with base R by the package itself. — myR_OSS","text":"","code":"myR_OSS(n, X)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/myR_OSS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"OSS with base R by the package itself. — myR_OSS","text":"n Subsample size. X matrix.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/myR_OSS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"OSS with base R by the package itself. — myR_OSS","text":"Subsample index.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/myRcpp_IBOSS.html","id":null,"dir":"Reference","previous_headings":"","what":"IBOSS with Rcpp-r-style by the package itself. — myRcpp_IBOSS","title":"IBOSS with Rcpp-r-style by the package itself. — myRcpp_IBOSS","text":"IBOSS Rcpp-r-style package .","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/myRcpp_IBOSS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"IBOSS with Rcpp-r-style by the package itself. — myRcpp_IBOSS","text":"","code":"myRcpp_IBOSS(n, X)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/myRcpp_IBOSS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"IBOSS with Rcpp-r-style by the package itself. — myRcpp_IBOSS","text":"n Subsample size. X data.frame matrix consists explanatory variables.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/myRcpp_IBOSS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"IBOSS with Rcpp-r-style by the package itself. — myRcpp_IBOSS","text":"Subsample index.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/myRcpp_cstyle_IBOSS.html","id":null,"dir":"Reference","previous_headings":"","what":"IBOSS with Rcpp-C++-style by the package itself. — myRcpp_cstyle_IBOSS","title":"IBOSS with Rcpp-C++-style by the package itself. — myRcpp_cstyle_IBOSS","text":"IBOSS Rcpp-C++-style package .","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/myRcpp_cstyle_IBOSS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"IBOSS with Rcpp-C++-style by the package itself. — myRcpp_cstyle_IBOSS","text":"","code":"myRcpp_cstyle_IBOSS(n, X)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/myRcpp_cstyle_IBOSS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"IBOSS with Rcpp-C++-style by the package itself. — myRcpp_cstyle_IBOSS","text":"n Subsample size. X data.frame matrix consists explanatory variables.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/myRcpp_cstyle_IBOSS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"IBOSS with Rcpp-C++-style by the package itself. — myRcpp_cstyle_IBOSS","text":"Subsample index.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/rComputeLoss.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute loss function for OSS (r-version) — rComputeLoss","title":"Compute loss function for OSS (r-version) — rComputeLoss","text":"Compute loss function OSS (r-version)","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/rComputeLoss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute loss function for OSS (r-version) — rComputeLoss","text":"","code":"rComputeLoss(candi, last_index, X, norm, p = ncol(X))"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/rComputeLoss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute loss function for OSS (r-version) — rComputeLoss","text":"candi index candidate set. last_index index seleted point last iteration. X whole data. norm Norm whole data. p Numbers columns data.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/rComputeLoss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute loss function for OSS (r-version) — rComputeLoss","text":"Loss every point candidate set.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/rL2norm.html","id":null,"dir":"Reference","previous_headings":"","what":"Get L2 norm (r-version) — rL2norm","title":"Get L2 norm (r-version) — rL2norm","text":"Get L2 norm matrix data frame.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/rL2norm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get L2 norm (r-version) — rL2norm","text":"","code":"rL2norm(X)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/rL2norm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get L2 norm (r-version) — rL2norm","text":"X matrix data.frame.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/rL2norm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get L2 norm (r-version) — rL2norm","text":"L2 norm X(every row).","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/r_IES.html","id":null,"dir":"Reference","previous_headings":"","what":"R Version of IES for Testing — r_IES","title":"R Version of IES for Testing — r_IES","text":"R Version IES Testing","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/r_IES.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"R Version of IES for Testing — r_IES","text":"","code":"r_IES(X, n, q, seed = NULL)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/r_IES.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"R Version of IES for Testing — r_IES","text":"X data.frame matrix consists explanatory variables. n Subsample size. q Hyperparamter divide axes. seed Random seed sampling.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/r_IES_compare.html","id":null,"dir":"Reference","previous_headings":"","what":"IES R-Version for Benchmarking — r_IES_compare","title":"IES R-Version for Benchmarking — r_IES_compare","text":"randomness, parts need randomly selected selected first indexed.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/r_IES_compare.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"IES R-Version for Benchmarking — r_IES_compare","text":"","code":"r_IES_compare(X, n, q)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/r_IES_compare.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"IES R-Version for Benchmarking — r_IES_compare","text":"X X data.frame matrix consists explanatory variables. n Subsample size. q Hyperparamter divide axes.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/rbottom_t_index.html","id":null,"dir":"Reference","previous_headings":"","what":"Find t smallest index of a vector. — rbottom_t_index","title":"Find t smallest index of a vector. — rbottom_t_index","text":"Find t smallest index vector.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/rbottom_t_index.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find t smallest index of a vector. — rbottom_t_index","text":"","code":"rbottom_t_index(loss, t)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/rbottom_t_index.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find t smallest index of a vector. — rbottom_t_index","text":"loss vector. t int","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/rbottom_t_index.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find t smallest index of a vector. — rbottom_t_index","text":"index t smallest element vector.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/rcppIBOSS.html","id":null,"dir":"Reference","previous_headings":"","what":"IBOSS with Rcpp-r-style by the package itself (myRcppIBOSS core c++ code) — rcppIBOSS","title":"IBOSS with Rcpp-r-style by the package itself (myRcppIBOSS core c++ code) — rcppIBOSS","text":"IBOSS Rcpp-r-style package (myRcppIBOSS core c++ code)","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/rcppIBOSS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"IBOSS with Rcpp-r-style by the package itself (myRcppIBOSS core c++ code) — rcppIBOSS","text":"","code":"rcppIBOSS(X, n)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/rcppIBOSS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"IBOSS with Rcpp-r-style by the package itself (myRcppIBOSS core c++ code) — rcppIBOSS","text":"X data.frame matrix consists explanatory variables. n Subsample size.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/rcppIBOSS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"IBOSS with Rcpp-r-style by the package itself (myRcppIBOSS core c++ code) — rcppIBOSS","text":"Subsample index.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/rcppOSS.html","id":null,"dir":"Reference","previous_headings":"","what":"OSS Rcpp-version by the package itself (OSS core code) — rcppOSS","title":"OSS Rcpp-version by the package itself (OSS core code) — rcppOSS","text":"OSS Rcpp-version package (OSS core code)","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/rcppOSS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"OSS Rcpp-version by the package itself (OSS core code) — rcppOSS","text":"","code":"rcppOSS(X, n)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/rcppOSS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"OSS Rcpp-version by the package itself (OSS core code) — rcppOSS","text":"X matrix. n Subsample size.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/rcppOSS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"OSS Rcpp-version by the package itself (OSS core code) — rcppOSS","text":"Subsample index.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/rcpp_cstyle_IBOSS.html","id":null,"dir":"Reference","previous_headings":"","what":"IBOSS with Rcpp-C++-style by the package itself (myRcpp_cstyle_IBOSS core c++ code) — rcpp_cstyle_IBOSS","title":"IBOSS with Rcpp-C++-style by the package itself (myRcpp_cstyle_IBOSS core c++ code) — rcpp_cstyle_IBOSS","text":"IBOSS Rcpp-C++-style package (myRcpp_cstyle_IBOSS core c++ code)","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/rcpp_cstyle_IBOSS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"IBOSS with Rcpp-C++-style by the package itself (myRcpp_cstyle_IBOSS core c++ code) — rcpp_cstyle_IBOSS","text":"","code":"rcpp_cstyle_IBOSS(X, n)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/rcpp_cstyle_IBOSS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"IBOSS with Rcpp-C++-style by the package itself (myRcpp_cstyle_IBOSS core c++ code) — rcpp_cstyle_IBOSS","text":"X data.frame matrix consists explanatory variables. n Subsample size.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/rcpp_cstyle_IBOSS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"IBOSS with Rcpp-C++-style by the package itself (myRcpp_cstyle_IBOSS core c++ code) — rcpp_cstyle_IBOSS","text":"Subsample index.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/scale01.html","id":null,"dir":"Reference","previous_headings":"","what":"Scale data to \\([-1, 1]\\) — scale01","title":"Scale data to \\([-1, 1]\\) — scale01","text":"Scale data \\([-1, 1]\\)","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/scale01.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scale data to \\([-1, 1]\\) — scale01","text":"","code":"scale01(X)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/scale01.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scale data to \\([-1, 1]\\) — scale01","text":"X data.frame matrix.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/scale01.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Scale data to \\([-1, 1]\\) — scale01","text":"Scaled X.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/scale01.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Scale data to \\([-1, 1]\\) — scale01","text":"","code":"X <- matrix(1:20, 5, 4) scale01(X) #>      [,1] [,2] [,3] [,4] #> [1,] 0.00 0.00 0.00 0.00 #> [2,] 0.25 0.25 0.25 0.25 #> [3,] 0.50 0.50 0.50 0.50 #> [4,] 0.75 0.75 0.75 0.75 #> [5,] 1.00 1.00 1.00 1.00"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/scale_neg_pos_1.html","id":null,"dir":"Reference","previous_headings":"","what":"Transform data to \\([-1,1]^p\\) — scale_neg_pos_1","title":"Transform data to \\([-1,1]^p\\) — scale_neg_pos_1","text":"Transform data \\([-1,1]^p\\)","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/scale_neg_pos_1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transform data to \\([-1,1]^p\\) — scale_neg_pos_1","text":"","code":"scale_neg_pos_1(X)"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/scale_neg_pos_1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transform data to \\([-1,1]^p\\) — scale_neg_pos_1","text":"X data.frame matrix explanatory variables.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/scale_neg_pos_1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transform data to \\([-1,1]^p\\) — scale_neg_pos_1","text":"Scaled X \\([-1,1]^p\\).","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/scale_neg_pos_1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Transform data to \\([-1,1]^p\\) — scale_neg_pos_1","text":"","code":"X <- matrix(rnorm(100), nrow = 20, ncol = 5) scaled_X <- scale_neg_pos_1(X) apply(scaled_X, 2, range) #>      [,1] [,2] [,3] [,4] [,5] #> [1,]   -1   -1   -1   -1   -1 #> [2,]    1    1    1    1    1"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/subsampling.html","id":null,"dir":"Reference","previous_headings":"","what":"Get subsample index. — subsampling","title":"Get subsample index. — subsampling","text":"unified interface retrieving subsample indexes","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/subsampling.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get subsample index. — subsampling","text":"","code":"subsampling(   y_name,   x_name = NULL,   data,   n,   pilot_n = NULL,   method = \"Unif\",   replace = TRUE,   seed = NULL,   seed_1 = NULL,   seed_2 = NULL,   na_method = NULL,   ... )"},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/subsampling.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get subsample index. — subsampling","text":"y_name character. name response variable data frame. x_name character. name explanatory variable data frame. Default variables except response variable data data frame containing response variables explanatory variables n Subsample size. pilot_n pilot sample size (method) method Subsamling methods: Unif: Random sampling. OSMAC_A: subsampling method based -optimal logistic regression proposed Wang et.al. (2018). OSMAC_L: subsampling method based L-optimal logistic regression proposed Wang et.al. (2018). IBOSS: subsampling method based D-optimal linear regression proposed Wang et.al. (2019). OSS : subsampling method based Orthogonal Array proposed Wang et.al.(2021). LowCon: subsampling method based Space-filling designs proposed Meng et.al.(2021). IES: subsampling method based Orthogonal Array proposed Zhang et.al.(2024). replace boolean. TRUE (default): Sampling replace. FALSE: Sampling without replace seed Random seed. Default NULL. seed_1 Random seed first stage sampling (two-phase subsampling needed). Default NULL. seed_2 Random seed second stage sampling (two-phase subsampling needed). Default NULL. na_method Method handle NA. ... Additional parameters setting methods. theta: Percentage data shrinkage LowCon. Default 1. q : Hyperparamter divide axes IES. Default 16.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/subsampling.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get subsample index. — subsampling","text":"numeric vector length n represent subsample index.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/reference/subsampling.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get subsample index. — subsampling","text":"","code":"data_binary <- data_binary_class subsampling(y_name = \"y\", data = data_binary, n = 30, method = \"Unif\", seed = 123) #>  [1] 2463 2511 8718 2986 1842 9334 3371 4761 6746 9819 2757 5107 9145 9209 2888 #> [16] 6170 2567 9642 9982 2980 1614  555 4469 9359 7789 9991 9097 1047 7067 3004 subsampling(y_name = \"y\", data = data_binary, n = 30, pilot_n = 100, method = \"OSMAC_A\",   seed_1 = 123, seed_2 = 456) #>  [1] 5684 1620 5372 8297 8863 9783 6483 6103 2702 5735 9382   40 9919 8623 2816 #> [16] 5035 6088 2006 4702 1993 4279 9827 8738 8892 7632 6836 6393 6405   99 3952 subsampling(y_name = \"y\", data = data_binary, n = 30, pilot_n = 100, method = \"OSMAC_L\",   seed_1 = 123, seed_2 = 456) #>  [1] 5813 1681 5372 8313 8863 9780 1630 6103 2702 5888 9382 9843 9913 8635 2816 #> [16] 5035 6211 2090 4702 2083 4385 9813 8776 8904 4425 6899 1615 6513   99 4076  data_numeric <- data_numeric_regression subsampling(y_name = \"y\", data = data_numeric, n = 100, method = \"IBOSS\") #>  [1]  183  226  395  419  584  666  711  758 1027 1144 1324 1445 1940 1946 1978 #> [16] 2018 2673 2982 3190 3395 3484 3612 3632 3638 3696 3816 3835 3896 3921 4256 #> [31] 4312 4405 4523 4551 4729 4938 5121 5226 5342 5410 5679 5770 5995 6089 6163 #> [46] 6170 6203 6250 6525 6964 6979 7053 7198 7407 7564 7633 7915 7935 7967 7992 #> [61] 8026 8088 8106 8156 8161 8267 8306 8501 8503 8521 8534 8694 8805 8841 9117 #> [76] 9211 9302 9364 9398 9456 9676 9946 9971 9989 1173 2344 5394 8438 8567 9239 #> [91] 1787 2104 2215 3121 7159 9133 subsampling(y_name = \"y\", data = data_numeric, n = 30, method = \"OSS\") #>  [1] 8841 8961 1902 7512   48 9867 6547 9784 3392 3622 5780 6594 1890 1850 8335 #> [16] 1254 6204 1257 4611 3831 4782 4919 1579 3404  718 7189 2060 4899  590 1800 subsampling(y_name = \"y\", data = data_numeric, n = 10, method = \"LowCon\", seed = 123, theta = 1) #>  [1] 6032 6633 4180 5093 6005 7093 3621 4429 1715 7143 subsampling(y_name = \"y\", data = data_numeric, n = 10, method = \"IES\", seed = 123, q = 16) #>  [1] 2876 7890 4440 9400 9813 2499 4939 8165 2224 4628"},{"path":"https://jieyinstat.github.io/dbsubsampling/news/index.html","id":"dbsubsampling-002","dir":"Changelog","previous_headings":"","what":"dbsubsampling 0.0.2","title":"dbsubsampling 0.0.2","text":"Add implementation OSS, LowCon IES. Add article simulation IES.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/news/index.html","id":"dbsubsampling-001","dir":"Changelog","previous_headings":"","what":"dbsubsampling 0.0.1","title":"dbsubsampling 0.0.1","text":"Implement methods. Begin IBOSS.","code":""},{"path":"https://jieyinstat.github.io/dbsubsampling/news/index.html","id":"dbsubsampling-0009001","dir":"Changelog","previous_headings":"","what":"dbsubsampling 0.0.0.9001","title":"dbsubsampling 0.0.0.9001","text":"Implement Unifand OSMAC. Add vignettes news.","code":""}]
